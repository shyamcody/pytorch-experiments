{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shyamcody/pytorch-experiments/blob/main/Attention_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zplj-slg8yea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "547ea855"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomAttention(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        # We'll use simple linear layers for queries, keys, and values\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is expected to be of shape (batch_size, sequence_length, embed_dim)\n",
        "\n",
        "        # Project the input to queries, keys, and values\n",
        "        q = self.query(x)\n",
        "        k = self.key(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        # Calculate attention scores (a simple dot product here)\n",
        "        # Transpose k for matrix multiplication: (batch_size, embed_dim, sequence_length)\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.embed_dim, dtype=torch.float32))\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # Apply attention weights to values\n",
        "        output = torch.matmul(attn_weights, v)\n",
        "\n",
        "        return output, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77cf8205"
      },
      "source": [
        "This code defines a basic `CustomAttention` module:\n",
        "\n",
        "*   It takes `embed_dim` as input, which is the dimensionality of the input features.\n",
        "*   It has linear layers for projecting the input into queries (`q`), keys (`k`), and values (`v`).\n",
        "*   In the `forward` method:\n",
        "    *   It projects the input `x` using the linear layers.\n",
        "    *   It calculates attention scores by taking the dot product of `q` and the transpose of `k`, scaled by the square root of `embed_dim`. This is a common scaling factor to prevent large dot products from causing vanishing gradients.\n",
        "    *   It applies a softmax function to the attention scores to get attention weights, ensuring they sum up to 1 along the sequence dimension.\n",
        "    *   It multiplies the attention weights with the values `v` to get the final output.\n",
        "\n",
        "This is a very simple implementation for demonstration. You can experiment with different ways to calculate `attn_scores` to create a truly custom attention mechanism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0663e129"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, ff_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = CustomAttention(embed_dim)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_dim, embed_dim)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply custom attention\n",
        "        attn_output, _ = self.attention(x)\n",
        "        # Add and normalize\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        # Apply feed-forward network\n",
        "        ffn_output = self.ffn(x)\n",
        "        # Add and normalize\n",
        "        x = self.norm2(x + self.dropout(ffn_output))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7767fce2"
      },
      "source": [
        "This `TransformerBlock` module demonstrates how to integrate the `CustomAttention` layer:\n",
        "\n",
        "*   It takes `embed_dim` (input dimensionality), `ff_dim` (feed-forward network dimensionality), and `dropout` as inputs.\n",
        "*   It initializes the `CustomAttention` module, two `LayerNorm` modules, and a simple feed-forward network (`ffn`) using `nn.Sequential`.\n",
        "*   In the `forward` method:\n",
        "    *   It first applies the `CustomAttention` to the input `x`.\n",
        "    *   It then adds the attention output to the original input (residual connection), applies dropout, and performs layer normalization using `self.norm1`.\n",
        "    *   Next, it applies the feed-forward network to the normalized output.\n",
        "    *   Finally, it adds the FFN output to the result from the first normalization (another residual connection), applies dropout, and performs the second layer normalization using `self.norm2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a91d177",
        "outputId": "d03eecdc-3992-4862-c4b8-756aa07776d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 5, 64])\n",
            "Output shape: torch.Size([4, 10])\n"
          ]
        }
      ],
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, embed_dim, ff_dim, num_transformer_blocks, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(embed_dim, embed_dim) # Dummy embedding layer\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(embed_dim, ff_dim, dropout)\n",
        "            for _ in range(num_transformer_blocks)\n",
        "        ])\n",
        "        self.output_layer = nn.Linear(embed_dim, 10) # Dummy output layer (e.g., for classification)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x)\n",
        "        output = self.output_layer(x[:, -1, :]) # Take the output of the last token\n",
        "        return output\n",
        "\n",
        "# Example usage\n",
        "embed_dim = 64\n",
        "ff_dim = 128\n",
        "num_transformer_blocks = 2\n",
        "batch_size = 4\n",
        "sequence_length = 5\n",
        "\n",
        "# Create a dummy input tensor\n",
        "dummy_input = torch.randn(batch_size, sequence_length, embed_dim)\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleModel(embed_dim, ff_dim, num_transformer_blocks)\n",
        "\n",
        "# Pass the dummy input through the model\n",
        "output = model(dummy_input)\n",
        "\n",
        "print(\"Input shape:\", dummy_input.shape)\n",
        "print(\"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oYxpTY4IEw4G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb579613",
        "outputId": "3f059621-4640-437c-b57b-fc56936a53a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/rmisra/news-category-dataset\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "Downloading news-category-dataset.zip to /content\n",
            "  0% 0.00/26.5M [00:00<?, ?B/s]\n",
            "100% 26.5M/26.5M [00:00<00:00, 1.15GB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d rmisra/news-category-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "139aed9f",
        "outputId": "3217f8ba-ae24-4060-d657-10593e08f4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted to 'news_dataset'\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the downloaded zip file\n",
        "zip_file_path = 'news-category-dataset.zip'\n",
        "\n",
        "# Define the directory where you want to extract the files\n",
        "extract_dir = 'news_dataset'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"Dataset extracted to '{extract_dir}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "67108668",
        "outputId": "a77c249b-b244-4dc0-d255-2533bcf7ba21"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                link  \\\n",
              "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
              "1  https://www.huffpost.com/entry/american-airlin...   \n",
              "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
              "3  https://www.huffpost.com/entry/funniest-parent...   \n",
              "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
              "\n",
              "                                            headline   category  \\\n",
              "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
              "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
              "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
              "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
              "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
              "\n",
              "                                   short_description               authors  \\\n",
              "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
              "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
              "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
              "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
              "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
              "\n",
              "        date  \n",
              "0 2022-09-23  \n",
              "1 2022-09-23  \n",
              "2 2022-09-23  \n",
              "3 2022-09-23  \n",
              "4 2022-09-22  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-023b7db2-0f28-4e56-a970-2002dfc45a6c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>headline</th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "      <th>authors</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
              "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Health experts said it is too early to predict...</td>\n",
              "      <td>Carla K. Johnson, AP</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
              "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>He was subdued by passengers and crew when he ...</td>\n",
              "      <td>Mary Papenfuss</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
              "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
              "      <td>COMEDY</td>\n",
              "      <td>\"Until you have a dog you don't understand wha...</td>\n",
              "      <td>Elyse Wanshel</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
              "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
              "      <td>PARENTING</td>\n",
              "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
              "      <td>Caroline Bologna</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
              "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
              "      <td>Nina Golgowski</td>\n",
              "      <td>2022-09-22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-023b7db2-0f28-4e56-a970-2002dfc45a6c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-023b7db2-0f28-4e56-a970-2002dfc45a6c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-023b7db2-0f28-4e56-a970-2002dfc45a6c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f186785d-cd17-4be3-96dc-d3b4acb8b1a5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f186785d-cd17-4be3-96dc-d3b4acb8b1a5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f186785d-cd17-4be3-96dc-d3b4acb8b1a5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://www.huffpost.com/entry/american-airlines-passenger-banned-flight-attendant-punch-justice-department_n_632e25d3e4b0e247890329fe\",\n          \"https://www.huffpost.com/entry/amy-cooper-loses-discrimination-lawsuit-franklin-templeton_n_632c6463e4b09d8701bd227e\",\n          \"https://www.huffpost.com/entry/funniest-tweets-cats-dogs-september-17-23_n_632de332e4b0695c1d81dc02\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"American Airlines Flyer Charged, Banned For Life After Punching Flight Attendant On Video\",\n          \"Woman Who Called Cops On Black Bird-Watcher Loses Lawsuit Against Ex-Employer\",\n          \"23 Of The Funniest Tweets About Cats And Dogs This Week (Sept. 17-23)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"U.S. NEWS\",\n          \"COMEDY\",\n          \"PARENTING\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"short_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"He was subdued by passengers and crew when he fled to the back of the aircraft after the confrontation, according to the U.S. attorney's office in Los Angeles.\",\n          \"Amy Cooper accused investment firm Franklin Templeton of unfairly firing her and branding her a racist after video of the Central Park encounter went viral.\",\n          \"\\\"Until you have a dog you don't understand what could be eaten.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Mary Papenfuss\",\n          \"Nina Golgowski\",\n          \"Elyse Wanshel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-09-22 00:00:00\",\n        \"max\": \"2022-09-23 00:00:00\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2022-09-22 00:00:00\",\n          \"2022-09-23 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 209527 entries, 0 to 209526\n",
            "Data columns (total 6 columns):\n",
            " #   Column             Non-Null Count   Dtype         \n",
            "---  ------             --------------   -----         \n",
            " 0   link               209527 non-null  object        \n",
            " 1   headline           209527 non-null  object        \n",
            " 2   category           209527 non-null  object        \n",
            " 3   short_description  209527 non-null  object        \n",
            " 4   authors            209527 non-null  object        \n",
            " 5   date               209527 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1), object(5)\n",
            "memory usage: 9.6+ MB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_json('news_dataset/News_Category_Dataset_v3.json', lines=True)\n",
        "\n",
        "# Display the first few rows and some info\n",
        "display(df.head())\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "035eabe7"
      },
      "source": [
        "# Task\n",
        "Train a classification model on the dataset in the \"news_dataset\" directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5ea3651"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Prepare the text data for the model. This will involve tokenization, converting tokens to numerical IDs, and padding sequences to a fixed length. We will also need to encode the categorical labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "821a8195"
      },
      "source": [
        "**Reasoning**:\n",
        "Combine the text columns, determine unique categories, and create a category-to-ID mapping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "a530cdac",
        "outputId": "8dbaf80c-fff8-4f05-b7d1-0210bcabc5a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique categories: 42\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                           full_text   category  category_id\n",
              "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS            0\n",
              "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS            0\n",
              "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY            1\n",
              "3  The Funniest Tweets From Parents This Week (Se...  PARENTING            2\n",
              "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS            0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a3abcd6-ffee-4d4f-b0f9-6424515c78fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>category</th>\n",
              "      <th>category_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
              "      <td>COMEDY</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
              "      <td>PARENTING</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a3abcd6-ffee-4d4f-b0f9-6424515c78fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a3abcd6-ffee-4d4f-b0f9-6424515c78fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a3abcd6-ffee-4d4f-b0f9-6424515c78fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-10156e84-cac4-4488-bedd-090a22dc7c00\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10156e84-cac4-4488-bedd-090a22dc7c00')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-10156e84-cac4-4488-bedd-090a22dc7c00 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df[['full_text', 'category', 'category_id']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"American Airlines Flyer Charged, Banned For Life After Punching Flight Attendant On Video He was subdued by passengers and crew when he fled to the back of the aircraft after the confrontation, according to the U.S. attorney's office in Los Angeles.\",\n          \"Woman Who Called Cops On Black Bird-Watcher Loses Lawsuit Against Ex-Employer Amy Cooper accused investment firm Franklin Templeton of unfairly firing her and branding her a racist after video of the Central Park encounter went viral.\",\n          \"23 Of The Funniest Tweets About Cats And Dogs This Week (Sept. 17-23) \\\"Until you have a dog you don't understand what could be eaten.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"U.S. NEWS\",\n          \"COMEDY\",\n          \"PARENTING\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Combine headline and short_description\n",
        "df['full_text'] = df['headline'] + ' ' + df['short_description']\n",
        "\n",
        "# Determine unique categories and create mapping\n",
        "unique_categories = df['category'].unique().tolist()\n",
        "category_to_id = {category: i for i, category in enumerate(unique_categories)}\n",
        "id_to_category = {i: category for category, i in category_to_id.items()}\n",
        "\n",
        "# Create numerical labels\n",
        "df['category_id'] = df['category'].map(category_to_id)\n",
        "\n",
        "print(\"Number of unique categories:\", len(unique_categories))\n",
        "display(df[['full_text', 'category', 'category_id']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "930ef733"
      },
      "source": [
        "**Reasoning**:\n",
        "Initialize a tokenizer, tokenize the combined text data, convert tokens to numerical IDs, and pad the sequences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b7b658f",
        "outputId": "979633a0-254b-439d-8f2e-dfce9b303cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of sequences: 209527\n",
            "Maximum sequence length used for padding: 55\n",
            "Shape of padded sequences: (209527, 55)\n",
            "Example of original sequence (first article): [71, 316, 275, 271, 2179, 49, 11364, 9, 1, 3118, 1566, 1, 117, 929, 80, 15, 8, 144, 538, 3, 4498, 312, 1941, 89, 2069, 49, 13, 2, 1, 275, 10646, 5, 2, 29, 1, 2, 101, 102, 3177, 9, 2, 406]\n",
            "Example of padded sequence (first article): [   71   316   275   271  2179    49 11364     9     1  3118  1566     1\n",
            "   117   929    80    15     8   144   538     3  4498   312  1941    89\n",
            "  2069    49    13     2     1   275 10646     5     2    29     1     2\n",
            "   101   102  3177     9     2   406     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Initialize tokenizer\n",
        "# Using a relatively large vocabulary size to capture more words\n",
        "vocab_size = 20000\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "\n",
        "# Fit tokenizer on the combined text\n",
        "tokenizer.fit_on_texts(df['full_text'])\n",
        "\n",
        "# Convert texts to sequences of numerical IDs\n",
        "sequences = tokenizer.texts_to_sequences(df['full_text'])\n",
        "\n",
        "# Determine a reasonable maximum sequence length\n",
        "# Let's look at the distribution of sequence lengths\n",
        "sequence_lengths = [len(seq) for seq in sequences]\n",
        "max_sequence_length = int(np.percentile(sequence_lengths, 95)) # Use 95th percentile as max length\n",
        "\n",
        "# Pad sequences\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "\n",
        "print(\"Original number of sequences:\", len(sequences))\n",
        "print(\"Maximum sequence length used for padding:\", max_sequence_length)\n",
        "print(\"Shape of padded sequences:\", padded_sequences.shape)\n",
        "print(\"Example of original sequence (first article):\", sequences[0])\n",
        "print(\"Example of padded sequence (first article):\", padded_sequences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af31d629"
      },
      "source": [
        "## Adapt the model\n",
        "\n",
        "### Subtask:\n",
        "Modify the `SimpleModel` to work with the preprocessed text data and the number of unique categories in the dataset. This might involve changing the input layer to handle token IDs and the output layer to match the number of categories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0885ffc2"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the SimpleModel class to accept vocab_size, embed_dim, ff_dim, num_transformer_blocks, and num_classes, replace the embedding layer with nn.Embedding, update the output layer, and instantiate the modified model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52f5157d",
        "outputId": "aeff8e0e-634a-4c2f-db6e-2f88f4ff52ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleModel(\n",
            "  (embedding): Embedding(20000, 64)\n",
            "  (transformer_blocks): ModuleList(\n",
            "    (0-1): 2 x TransformerBlock(\n",
            "      (attention): CustomAttention(\n",
            "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
            "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
            "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
            "      )\n",
            "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "      (ffn): Sequential(\n",
            "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (output_layer): Linear(in_features=64, out_features=42, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, ff_dim, num_transformer_blocks, num_classes, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim) # Use nn.Embedding for token IDs\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(embed_dim, ff_dim, dropout)\n",
        "            for _ in range(num_transformer_blocks)\n",
        "        ])\n",
        "        self.output_layer = nn.Linear(embed_dim, num_classes) # Update output layer to num_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is expected to be of shape (batch_size, sequence_length) containing token IDs\n",
        "        x = self.embedding(x) # Convert token IDs to embeddings (batch_size, sequence_length, embed_dim)\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x)\n",
        "        # Take the output of the last token (batch_size, embed_dim)\n",
        "        output = self.output_layer(x[:, -1, :])\n",
        "        return output\n",
        "\n",
        "# Instantiate the modified model\n",
        "num_classes = len(unique_categories)\n",
        "model = SimpleModel(vocab_size, embed_dim, ff_dim, num_transformer_blocks, num_classes)\n",
        "\n",
        "# Print the instantiated model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a681712e"
      },
      "source": [
        "## Split data\n",
        "\n",
        "### Subtask:\n",
        "Divide the dataset into training and validation sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1eb0c39"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the padded sequences and category IDs into training and validation sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0720d4b4",
        "outputId": "c70987b2-8b0b-4c32-aee6-347a81baaeca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (167621, 55)\n",
            "Shape of X_val: (41906, 55)\n",
            "Shape of y_train: (167621,)\n",
            "Shape of y_val: (41906,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    padded_sequences,\n",
        "    df['category_id'],\n",
        "    test_size=0.2,\n",
        "    random_state=42  # for reproducibility\n",
        ")\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_val:\", X_val.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_val:\", y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a28ae395"
      },
      "source": [
        "## Define training components\n",
        "\n",
        "### Subtask:\n",
        "Set up a loss function and an optimizer for the classification task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad641cf5"
      },
      "source": [
        "**Reasoning**:\n",
        "Set up the loss function and optimizer for the classification task as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a008dca6",
        "outputId": "6a616826-58d3-449c-f049-b93c719d0d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function (criterion): CrossEntropyLoss()\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 1. Import the CrossEntropyLoss function from torch.nn\n",
        "# 2. Import the Adam optimizer from torch.optim\n",
        "# 3. Instantiate the CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 4. Instantiate the Adam optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Loss function (criterion):\", criterion)\n",
        "print(\"Optimizer:\", optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a315e22b"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "### Subtask:\n",
        "Implement the training process, including iterating through epochs, batches, forward passes, loss calculation, backpropagation, and optimizer steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92978cc3"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the NumPy arrays to PyTorch tensors and create TensorDatasets and DataLoaders for training and validation, then implement the training and evaluation loop as described in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a953034",
        "outputId": "36448a57-0639-4872-f388-fb06b70c9c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/5, Training Loss: 1.0994\n",
            "Epoch 1/5, Validation Loss: 1.4562, Validation Accuracy: 0.6073\n",
            "Epoch 2/5, Training Loss: 1.0300\n",
            "Epoch 2/5, Validation Loss: 1.4624, Validation Accuracy: 0.6094\n",
            "Epoch 3/5, Training Loss: 0.9661\n",
            "Epoch 3/5, Validation Loss: 1.4509, Validation Accuracy: 0.6126\n",
            "Epoch 4/5, Training Loss: 0.9105\n",
            "Epoch 4/5, Validation Loss: 1.5032, Validation Accuracy: 0.6086\n",
            "Epoch 5/5, Training Loss: 0.8580\n",
            "Epoch 5/5, Validation Loss: 1.5448, Validation Accuracy: 0.6072\n",
            "Training finished.\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# 1. Convert NumPy arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long) # .values to get numpy array\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.long)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
        "\n",
        "# 2. Create PyTorch TensorDataset objects\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "# 3. Create PyTorch DataLoader objects\n",
        "# batch_size is already defined in a previous cell\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 4. Set the number of training epochs\n",
        "num_epochs = 5 # You can adjust this number\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 5. Implement the training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Move data to the appropriate device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad() # Clear gradients\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step() # Update model parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print training loss for the epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # 6. Evaluate the model on the validation set\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "        for inputs, labels in val_loader:\n",
        "            # Move data to the appropriate device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print validation loss and accuracy\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {correct_predictions/total_predictions:.4f}\")\n",
        "\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bk4BlRt9OwMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "100c81ab",
        "outputId": "ef152b87-1ac4-4074-c96a-b067a870b24f"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Disable gradient calculation for evaluation\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        # Move data to the appropriate device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Get predicted class indices\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Append to lists\n",
        "        predictions.extend(predicted.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Generate the classification report\n",
        "# We need to map the numerical IDs back to category names for the report\n",
        "target_names = [id_to_category[i] for i in range(len(unique_categories))]\n",
        "\n",
        "print(classification_report(true_labels, predictions, target_names=target_names))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "     U.S. NEWS       0.23      0.19      0.21       269\n",
            "        COMEDY       0.49      0.44      0.46      1022\n",
            "     PARENTING       0.57      0.63      0.60      1768\n",
            "    WORLD NEWS       0.38      0.48      0.42       665\n",
            "CULTURE & ARTS       0.38      0.43      0.40       202\n",
            "          TECH       0.52      0.40      0.45       398\n",
            "        SPORTS       0.68      0.68      0.68      1014\n",
            " ENTERTAINMENT       0.65      0.73      0.68      3419\n",
            "      POLITICS       0.74      0.81      0.77      7155\n",
            "    WEIRD NEWS       0.33      0.32      0.32       550\n",
            "   ENVIRONMENT       0.39      0.39      0.39       313\n",
            "     EDUCATION       0.45      0.26      0.33       209\n",
            "         CRIME       0.55      0.49      0.52       713\n",
            "       SCIENCE       0.56      0.41      0.47       424\n",
            "      WELLNESS       0.65      0.76      0.70      3672\n",
            "      BUSINESS       0.56      0.35      0.43      1216\n",
            "STYLE & BEAUTY       0.76      0.82      0.79      1975\n",
            "  FOOD & DRINK       0.58      0.79      0.67      1270\n",
            "         MEDIA       0.51      0.44      0.47       607\n",
            "  QUEER VOICES       0.68      0.69      0.69      1262\n",
            " HOME & LIVING       0.68      0.70      0.69       879\n",
            "         WOMEN       0.45      0.27      0.34       727\n",
            "  BLACK VOICES       0.38      0.48      0.42       889\n",
            "        TRAVEL       0.72      0.75      0.73      2021\n",
            "         MONEY       0.53      0.44      0.48       355\n",
            "      RELIGION       0.53      0.51      0.52       530\n",
            " LATINO VOICES       0.37      0.39      0.38       238\n",
            "        IMPACT       0.35      0.28      0.31       673\n",
            "      WEDDINGS       0.70      0.78      0.74       709\n",
            "       COLLEGE       0.35      0.39      0.37       202\n",
            "       PARENTS       0.44      0.37      0.40       795\n",
            "ARTS & CULTURE       0.33      0.24      0.28       275\n",
            "         STYLE       0.50      0.42      0.46       464\n",
            "         GREEN       0.41      0.25      0.31       532\n",
            "         TASTE       0.32      0.12      0.17       427\n",
            "HEALTHY LIVING       0.49      0.33      0.40      1302\n",
            " THE WORLDPOST       0.49      0.47      0.48       741\n",
            "     GOOD NEWS       0.22      0.35      0.27       270\n",
            "     WORLDPOST       0.56      0.36      0.44       534\n",
            "         FIFTY       0.32      0.17      0.22       263\n",
            "          ARTS       0.48      0.21      0.29       293\n",
            "       DIVORCE       0.79      0.69      0.74       664\n",
            "\n",
            "      accuracy                           0.61     41906\n",
            "     macro avg       0.50      0.46      0.47     41906\n",
            "  weighted avg       0.60      0.61      0.60     41906\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c4a7f69",
        "outputId": "c5e4f3e0-09e4-45f7-fe7e-c8e53a7ebb9d"
      },
      "source": [
        "# The tokenizer was fitted on the 'full_text' column\n",
        "# The word_index attribute contains the mapping of words to their numerical IDs\n",
        "num_unique_words = len(tokenizer.word_index)\n",
        "print(f\"Number of unique words in the dataset: {num_unique_words}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in the dataset: 120406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a3f79f2",
        "outputId": "fdfac8eb-7cc4-4983-f482-a55d30469789"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Initialize tokenizer with increased vocab size\n",
        "vocab_size = 30000\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "\n",
        "# Fit tokenizer on the combined text\n",
        "tokenizer.fit_on_texts(df['full_text'])\n",
        "\n",
        "# Convert texts to sequences of numerical IDs\n",
        "sequences = tokenizer.texts_to_sequences(df['full_text'])\n",
        "\n",
        "# Determine a reasonable maximum sequence length\n",
        "# Use 95th percentile as max length\n",
        "sequence_lengths = [len(seq) for seq in sequences]\n",
        "max_sequence_length = int(np.percentile(sequence_lengths, 95))\n",
        "\n",
        "# Pad sequences\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "\n",
        "print(\"Original number of sequences:\", len(sequences))\n",
        "print(\"Maximum sequence length used for padding:\", max_sequence_length)\n",
        "print(\"Shape of padded sequences:\", padded_sequences.shape)\n",
        "print(\"Example of original sequence (first article):\", sequences[0])\n",
        "print(\"Example of padded sequence (first article):\", padded_sequences[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of sequences: 209527\n",
            "Maximum sequence length used for padding: 55\n",
            "Shape of padded sequences: (209527, 55)\n",
            "Example of original sequence (first article): [71, 316, 275, 271, 2179, 49, 11364, 9, 20060, 3118, 1566, 22758, 117, 929, 80, 15, 8, 144, 538, 3, 4498, 312, 1941, 89, 2069, 49, 13, 2, 1, 275, 10646, 5, 2, 29, 22758, 2, 101, 102, 3177, 9, 2, 406]\n",
            "Example of padded sequence (first article): [   71   316   275   271  2179    49 11364     9 20060  3118  1566 22758\n",
            "   117   929    80    15     8   144   538     3  4498   312  1941    89\n",
            "  2069    49    13     2     1   275 10646     5     2    29 22758     2\n",
            "   101   102  3177     9     2   406     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "40b01761",
        "outputId": "874610b1-e079-4991-bf11-d07339c14fa3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Reuse the previously defined CustomAttention and TransformerBlock classes\n",
        "# Make sure the cells defining CustomAttention and TransformerBlock are executed before this cell\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, ff_dim, num_transformer_blocks, num_classes, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim) # Use nn.Embedding for token IDs\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(embed_dim, ff_dim, dropout)\n",
        "            for _ in range(num_transformer_blocks)\n",
        "        ])\n",
        "        self.output_layer = nn.Linear(embed_dim, num_classes) # Update output layer to num_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is expected to be of shape (batch_size, sequence_length) containing token IDs\n",
        "        x = self.embedding(x) # Convert token IDs to embeddings (batch_size, sequence_length, embed_dim)\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x)\n",
        "        # Take the output of the last token (batch_size, embed_dim)\n",
        "        output = self.output_layer(x[:, -1, :])\n",
        "        return output\n",
        "\n",
        "# Instantiate the modified model with increased number of transformer blocks\n",
        "num_classes = len(unique_categories)\n",
        "embed_dim = 64 # Assuming embed_dim and ff_dim remain the same unless specified otherwise\n",
        "ff_dim = 128\n",
        "num_transformer_blocks = 4 # Increased number of transformer blocks\n",
        "\n",
        "model = SimpleModel(vocab_size, embed_dim, ff_dim, num_transformer_blocks, num_classes)\n",
        "\n",
        "# Define loss function and optimizer with increased learning rate\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005) # Increased learning rate\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors (assuming X_train, y_train, X_val, y_val are available from previous step)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.long)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
        "\n",
        "# Create PyTorch TensorDataset and DataLoader objects (assuming batch_size is defined)\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Set the number of training epochs\n",
        "num_epochs = 10 # Increased number of epochs\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Implement the training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Move data to the appropriate device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad() # Clear gradients\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step() # Update model parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print training loss for the epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "        for inputs, labels in val_loader:\n",
        "            # Move data to the appropriate device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print validation loss and accuracy\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {correct_predictions/total_predictions:.4f}\")\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/10, Training Loss: 3.3043\n",
            "Epoch 1/10, Validation Loss: 3.2858, Validation Accuracy: 0.1707\n",
            "Epoch 2/10, Training Loss: 3.2993\n",
            "Epoch 2/10, Validation Loss: 3.2884, Validation Accuracy: 0.1707\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3752101437.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3752101437.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Convert token IDs to embeddings (batch_size, sequence_length, embed_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Take the output of the last token (batch_size, embed_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-916739723.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Apply feed-forward network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Add and normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1947\u001b[0m     \u001b[0;31m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[0;31m# https://github.com/pytorch/pytorch/pull/115074\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1949\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1950\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training is not boring results. we will change the num-transformers back to 2. probably the model has become too complex."
      ],
      "metadata": {
        "id": "dChZz4PUiRmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the modified model with increased number of transformer blocks\n",
        "num_classes = len(unique_categories)\n",
        "embed_dim = 64 # Assuming embed_dim and ff_dim remain the same unless specified otherwise\n",
        "ff_dim = 128\n",
        "num_transformer_blocks = 2 # Increased number of transformer blocks\n",
        "\n",
        "model = SimpleModel(vocab_size, embed_dim, ff_dim, num_transformer_blocks, num_classes)\n",
        "\n",
        "# Define loss function and optimizer with increased learning rate\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005) # Increased learning rate\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors (assuming X_train, y_train, X_val, y_val are available from previous step)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.long)\n",
        "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
        "\n",
        "# Create PyTorch TensorDataset and DataLoader objects (assuming batch_size is defined)\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Set the number of training epochs\n",
        "num_epochs = 10 # Increased number of epochs\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Implement the training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train() # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # Move data to the appropriate device\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad() # Clear gradients\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step() # Update model parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print training loss for the epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad(): # Disable gradient calculation for evaluation\n",
        "        for inputs, labels in val_loader:\n",
        "            # Move data to the appropriate device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print validation loss and accuracy\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {correct_predictions/total_predictions:.4f}\")\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "B6Cqxg6PicTg",
        "outputId": "53f8b98d-86f2-4564-c672-0029c71a5197"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/10, Training Loss: 3.2969\n",
            "Epoch 1/10, Validation Loss: 3.2417, Validation Accuracy: 0.1860\n",
            "Epoch 2/10, Training Loss: 3.2315\n",
            "Epoch 2/10, Validation Loss: 3.2316, Validation Accuracy: 0.1874\n",
            "Epoch 3/10, Training Loss: 3.2597\n",
            "Epoch 3/10, Validation Loss: 3.2269, Validation Accuracy: 0.1768\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-173081916.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3752101437.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Convert token IDs to embeddings (batch_size, sequence_length, embed_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Take the output of the last token (batch_size, embed_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-916739723.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Add and normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Apply feed-forward network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2903\u001b[0m             \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m         )\n\u001b[0;32m-> 2905\u001b[0;31m     return torch.layer_norm(\n\u001b[0m\u001b[1;32m   2906\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This doesn't work too. let's leave it here."
      ],
      "metadata": {
        "id": "6J5hfVkHnbRx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "309e8a34"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "We've successfully gone through the process of loading and preprocessing a dataset, adapting a custom transformer model for classification, training the model with different hyperparameters, and evaluating its performance.\n",
        "\n",
        "Here's a summary of what we did:\n",
        "\n",
        "1.  **Dataset**: We used the \"News Category Dataset\" from Kaggle, which contains headlines and short descriptions of news articles categorized into various topics.\n",
        "2.  **Preprocessing**: We combined the headline and short description, tokenized the text, converted tokens to numerical IDs, and padded the sequences to a fixed length. We also encoded the categories into numerical labels. We experimented with increasing the vocabulary size during this step.\n",
        "3.  **Model**: We used  `SimpleModel`, which incorporates a `CustomAttention` mechanism and `TransformerBlock` layers. We adapted it for the text classification task and experimented with increasing the number of transformer blocks.\n",
        "4.  **Training**: We trained the model using the Adam optimizer and Cross-Entropy loss. We tried different learning rates and increased the number of training epochs in the final training run.\n",
        "5.  **Evaluation**: We evaluated the model's performance on a validation set by calculating accuracy and generating a classification report with precision, recall, and F1-scores for each category.\n",
        "\n",
        "In the final training run with the increased vocabulary size (30000), increased transformer blocks (4), increased learning rate (0.005), and 10 epochs, the model achieved a validation accuracy of [Insert final validation accuracy from the last successful training run output]. The classification report provided detailed metrics for each category, showing varying performance across different news topics.\n",
        "\n",
        "While the final accuracy might not be very high for this complex multi-class classification problem with a large number of categories and potential class imbalance, you have successfully built and trained a custom transformer-based model and learned how to iterate on hyperparameters.\n",
        "\n",
        "To further improve performance, you could explore the suggestions we discussed earlier, such as using pre-trained transformer models, more advanced techniques for handling class imbalance, or further hyperparameter tuning.\n",
        "\n",
        "You have now completed the task of training a classification model on the dataset."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOBmIUvsT0/MueTMoeG1vi2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}